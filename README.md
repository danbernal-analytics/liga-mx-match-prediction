# ‚öΩ Liga MX Match Probability Estimator
**Modelado probabil√≠stico y cuantificaci√≥n de incertidumbre en Football Analytics**

`dashboard link:` https://ligamx-match-prediction-vlpu.onrender.com/

## üéØ Objetivo del Proyecto
El f√∫tbol es un deporte de baja frecuencia de eventos y alta varianza. El objetivo de este proyecto no es realizar predicciones deterministas (ganar/perder), sino construir un modelo estad√≠stico calibrado que estime probabilidades reales para los resultados: **Victoria Local**, **Empate** y **Victoria Visitante**.

## ‚öôÔ∏è Metodolog√≠a y Feature Engineering

### 1. Integridad Temporal (Anti-Leakage)
Se implement√≥ un protocolo estricto de validaci√≥n temporal.
* **Corte temporal:** `2025-01-01`.
* **Entrenamiento:** Datos hist√≥ricos 2012-2024 (4070 partidos).
* **Test:** Temporada 2025 en adelante (196 partidos).
* **Rolling Windows:** Todas las m√©tricas de forma se calcularon con un `shift(1)` para garantizar que el modelo solo \"vea\" informaci√≥n disponible antes del pitazo inicial.

### 2. Variables Din√°micas
En lugar de promedios globales, se generaron features de ventanas m√≥viles (5 partidos) para capturar el *momentum*:
* `diff_form_5`: Diferencia de puntos obtenidos en los √∫ltimos 5 juegos.
* `diff_goals_for/against`: Diferencia en eficiencia ofensiva y defensiva reciente.

### 3. Jerarqu√≠a Estructural (Tiering)
Se cre√≥ un **Ranking Hist√≥rico** dividiendo a los equipos en 3 Tiers (√âlite, Medio, Bajo) basado en su *win rate* y diferencia de goles hist√≥rica.
* **Impacto:** La variable `diff_tier` (Diferencia de Jerarqu√≠a) result√≥ ser la caracter√≠stica m√°s importante del modelo (consistentemente destacada como una de las variables m√°s influyentes), validando que la historia pesa m√°s que la racha reciente en la Liga MX.

## üìä Resultados y Evaluaci√≥n
La m√©trica principal de √©xito fue el **Log Loss**, que penaliza la incertidumbre y premia la calibraci√≥n.

| Modelo | Log Loss | Observaci√≥n |
| :--- | :--- | :--- |
| **Baseline (Frecuencia Hist√≥rica)** | `1.0578` | Probabilidad "ciega" basada solo en local√≠a. |
| **XGBoost (Calibrado)** | `1.0145` | Ligero sobreajuste por la complejidad del modelo. |
| **Logistic Regression (Final)** | **`1.0103`** | **Mejor rendimiento y generalizaci√≥n.** |

**Conclusi√≥n T√©cnica:**
A pesar de la popularidad de los modelos de Boosting, la **Regresi√≥n Log√≠stica** demostr√≥ ser superior para este volumen de datos. Su naturaleza lineal captur√≥ eficientemente la ventaja de local√≠a (coeficiente positivo consistente con la ventaja hist√≥rica de local√≠a) y la jerarqu√≠a de los equipos, ofreciendo probabilidades m√°s robustas y menos propensas al ruido que XGBoost.

## üõ†Ô∏è Stack Tecnol√≥gico
* **Lenguaje:** Python.
* **Data Processing:** Pandas, NumPy (Manejo de series temporales y rolling windows).
* **Machine Learning:** Scikit-learn (LogisticRegression, CalibratedClassifierCV), XGBoost.
* **Visualizaci√≥n:** Matplotlib, Seaborn (Curvas de calibraci√≥n y Feature Importance).
* **Despliegue:** Streamlit (Dashboard interactivo).

---
Desarrollado por: Dan Bernal
Data Analyst | Tactical & Performance | Probabilistic Modeling
